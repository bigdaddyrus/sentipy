#install the necessary packages
install.packages("twitteR")
install.packages("wordcloud")
install.packages("tm")
library("twitteR")
library("wordcloud")
library("tm")
CONSUMER_KEY <- 'xKxVsn3alfG8SI4brUZEw4VxE'
CONSUMER_SECRET <- 'FUNF6SRuMvflsBjpcLBxb0KWWJY0t1bEyJjyzJavysBYtephIR'
OAUTH_TOKEN <- '2932353696-X7jlMqvqiw7gZJnVun2j1NKwyF7SofbEgiB5Tsd'
OAUTH_TOKEN_SECRET <- 'KdQ5FfRCJTP2umBUhcuzTIP44mvPPgp8BfJnxPUqx7Qoh'
#to get your consumerKey and consumerSecret see the twitteR documentation for instructions
consumer_key <- CONSUMER_KEY
consumer_secret <- CONSUMER_SECRET
access_token <- OAUTH_TOKEN
access_secret <- OAUTH_TOKEN_SECRET
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
library(httr)
oauth_endpoints("twitter")
myapp <- oauth_app("twitter",
key = "TYrWFPkFAkn4G5BbkWINYw",
secret = "qjOkmKYU9kWfUFWmekJuu5tztE9aEfLbt26WlhZL8"
)
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
library(httpuv)
#install the necessary packages
install.packages("twitteR")
install.packages("wordcloud")
install.packages("tm")
library("twitteR")
library("wordcloud")
library("tm")
CONSUMER_KEY <- 'kdhXPbiLI8XCy4HiyfMadBIX3'
CONSUMER_SECRET <- '6s4QmR5vJ2E0YJME2oDTvyW8Vf1i5Euz92OXgekNKWB1soDgQR'
OAUTH_TOKEN <- '2932353696-VqGPWM5j3V7gLqLMquKPwn1NApDKdWStOlQDsBi'
OAUTH_TOKEN_SECRET <- 'dmWUfdNpiqDj1p4ar1jyeRWANSbtebFWHvZ2rySM4asXs'
#to get your consumerKey and consumerSecret see the twitteR documentation for instructions
consumer_key <- CONSUMER_KEY
consumer_secret <- CONSUMER_SECRET
access_token <- OAUTH_TOKEN
access_secret <- OAUTH_TOKEN_SECRET
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
#the cainfo parameter is necessary only on Windows
r_stats <- searchTwitter("#Rstats", n=1500, cainfo="cacert.pem")
#should get 1500
length(r_stats)
#[1] 1500
install.packages("twitteR")
install.packages("wordcloud")
install.packages("tm")
install.packages("wordcloud")
install.packages("tm")
install.packages("tm")
r_stats
r_stats <- searchTwitter("#Rstats", n=1500, cainfo="cacert.pem")
r_stats <- searchTwitter("#Rstats", n=1500)
r_stats
# function score.sentiment
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
# Parameters
# sentences: vector of text to score
# pos.words: vector of words of postive sentiment
# neg.words: vector of words of negative sentiment
# .progress: passed to laply() to control of progress bar
# create simple array of scores with laply
scores = laply(sentences,
function(sentence, pos.words, neg.words)
{
# remove punctuation
sentence = gsub("[[:punct:]]", "", sentence)
# remove control characters
sentence = gsub("[[:cntrl:]]", "", sentence)
# remove digits?
sentence = gsub('\\d+', '', sentence)
# define error handling function when trying tolower
tryTolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
sentence = sapply(sentence, tryTolower)
# split sentence into words with str_split (stringr package)
word.list = str_split(sentence, "\\s+")
words = unlist(word.list)
# compare words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# final score
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
# data frame with scores for each sentence
scores.df = data.frame(text=sentences, score=scores)
return(scores.df)
}
# required pakacges
library(RCurl)
library(twitteR)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(ROAuth)
library(stringr)
library(httr)
set
#wine_tweets = searchTwitter("wine", n=500, lang="en")
aal_tweets = searchTwitter("$aal", n=500, lang="en")
dal_tweets = searchTwitter("$dal", n=500, lang="en")
ual_tweets = searchTwitter("$ual  ", n=500, lang="en")
# get text
aal_txt = sapply(aal_tweets, function(x) x$getText())
dal_txt = sapply(dal_tweets, function(x) x$getText())
ual_txt = sapply(ual_tweets, function(x) x$getText())
nd = c(length(aal_txt), length(dal_txt), length(ual_txt))
# join texts
firms = c(aal_txt, dal_txt, ual_txt)
# remove at people
firms = gsub("@\\w+", "", firms)
# remove punctuation
firms = gsub("[[:punct:]]", "", firms)
# remove numbers
firms = gsub("[[:digit:]]", "", firms)
# remove html links
firms = gsub("http\\w+", "", firms)
# remove unnecessary spaces
firms = gsub("[ \t]{2,}", "", firms)
firms = gsub("^\\s+|\\s+$", "", firms)
# apply function score.sentiment
scores = score.sentiment(firms, pos, neg, .progress='text')
# add variables to data frame
scores$firm = factor(rep(c("aal", "dal", "ual "), nd))
scores$very.pos = as.numeric(scores$score >= 2)
scores$very.neg = as.numeric(scores$score <= -2)
# join texts
firms = c(aal_txt, dal_txt, ual_txt)
# remove at people
firms = gsub("@\\w+", "", firms)
# remove punctuation
firms = gsub("[[:punct:]]", "", firms)
# remove numbers
firms = gsub("[[:digit:]]", "", firms)
# remove html links
firms = gsub("http\\w+", "", firms)
# remove unnecessary spaces
firms = gsub("[ \t]{2,}", "", firms)
firms = gsub("^\\s+|\\s+$", "", firms)
# apply function score.sentiment
scores = score.sentiment(firms, pos, neg, .progress='text')
# add variables to data frame
scores$firm = factor(rep(c("aal", "dal", "ual "), nd))
scores$very.pos = as.numeric(scores$score >= 2)
scores$very.neg = as.numeric(scores$score <= -2)
# apply function score.sentiment
scores = score.sentiment(firms, pos, neg, .progress='text')
getwd()
setwd("documents/rcode")
# function score.sentiment
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
# Parameters
# sentences: vector of text to score
# pos.words: vector of words of postive sentiment
# neg.words: vector of words of negative sentiment
# .progress: passed to laply() to control of progress bar
# create simple array of scores with laply
scores = laply(sentences,
function(sentence, pos.words, neg.words)
{
# remove punctuation
sentence = gsub("[[:punct:]]", "", sentence)
# remove control characters
sentence = gsub("[[:cntrl:]]", "", sentence)
# remove digits?
sentence = gsub('\\d+', '', sentence)
# define error handling function when trying tolower
tryTolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
sentence = sapply(sentence, tryTolower)
# split sentence into words with str_split (stringr package)
word.list = str_split(sentence, "\\s+")
words = unlist(word.list)
# compare words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# final score
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
# data frame with scores for each sentence
scores.df = data.frame(text=sentences, score=scores)
return(scores.df)
}
scores = score.sentiment(firms, pos, neg, .progress='text')
# import positive and negative words
pos = readLines("positive_words.txt")
neg = readLines("negative_words.txt")
# apply function score.sentiment
scores = score.sentiment(firms, pos, neg, .progress='text')
# add variables to data frame
scores$firm = factor(rep(c("aal", "dal", "ual "), nd))
scores$very.pos = as.numeric(scores$score >= 2)
scores$very.neg = as.numeric(scores$score <= -2)
# how many very positives and very negatives
numpos = sum(scores$very.pos)
numneg = sum(scores$very.neg)
# global score
global_score = round( 100 * numpos / (numpos + numneg) )
# colors
cols = c("#7CAE00", "#00BFC4", "#F8766D")
names(cols) = c("aal", "dal", "ual  ")
# boxplot
ggplot(scores, aes(x=firm, y=score, group=firm)) +
geom_boxplot(aes(fill=firm)) +
scale_fill_manual(values=cols) +
geom_jitter(colour="gray40",
position=position_jitter(width=0.2), alpha=0.3)
# barplot of average score
meanscore = tapply(scores$score, scores$firm, mean)
df = data.frame(firm=names(meanscore), meanscore=meanscore)
df$firms <- reorder(df$firm, df$meanscore)
ggplot(df, aes(y=meanscore, x=firms)) + geom_bar(stat="identity")
?wordcloud
wordcloud(firms)
wordcloud(aal_text)
wordcloud(aal_txt)
wordcloud(dal_txt)
wordcloud(ual_txt)
wordcloud(dal_txt)
dal_txt
aal_tweets
aal_tweets[1]
str_split("hello how are you?")
?str_split
?match
??match
scores = score.sentiment_Sent140(firms, pos, neg, .progress='text')
# function score.sentiment
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
# Parameters
# sentences: vector of text to score
# pos.words: vector of words of postive sentiment
# neg.words: vector of words of negative sentiment
# .progress: passed to laply() to control of progress bar
# create simple array of scores with laply
scores = laply(sentences,
function(sentence, pos.words, neg.words)
{
# remove punctuation
sentence = gsub("[[:punct:]]", "", sentence)
# remove control characters
sentence = gsub("[[:cntrl:]]", "", sentence)
# remove digits?
sentence = gsub('\\d+', '', sentence)
# define error handling function when trying tolower
tryTolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
sentence = sapply(sentence, tryTolower)
# split sentence into words with str_split (stringr package)
word.list = str_split(sentence, "\\s+")
words = unlist(word.list)
# compare words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# final score
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
# data frame with scores for each sentence
scores.df = data.frame(text=sentences, score=scores)
return(scores.df)
}
# function score.sentiment
score.sentiment_Sent140 = function(sentences, pos.words, neg.words, .progress='none')
{
# Parameters
# sentences: vector of text to score
# pos.words: vector of words of postive sentiment
# neg.words: vector of words of negative sentiment
# .progress: passed to laply() to control of progress bar
# create simple array of scores with laply
scores = laply(sentences,
function(sentence, pos.words, neg.words)
{
# remove punctuation
sentence = gsub("[[:punct:]]", "", sentence)
# remove control characters
sentence = gsub("[[:cntrl:]]", "", sentence)
# remove digits?
sentence = gsub('\\d+', '', sentence)
# define error handling function when trying tolower
tryTolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
sentence = sapply(sentence, tryTolower)
# split sentence into words with str_split (stringr package)
word.list = str_split(sentence, "\\s+")
words = unlist(word.list)
# compare words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# final score
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
# data frame with scores for each sentence
scores.df = data.frame(text=sentences, score=scores)
return(scores.df)
}
scores = score.sentiment_Sent140(firms, pos, neg, .progress='text')
debugSource('~/Documents/RCode/score.sentiment_Sent140.r')
scores = score.sentiment_Sent140(firms, pos, neg, .progress='text')
sent140_unigrams=readlines("documents/RCode/unigrams-pmilexicon.txt")
library(RCurl)
library(twitteR)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(ROAuth)
library(stringr)
library(httr)
sent140_unigrams=readlines("documents/RCode/unigrams-pmilexicon.txt")
sent140_unigrams=readLines("documents/RCode/unigrams-pmilexicon.txt")
sent140_unigrams=readLines("documents/RCode/sent140/unigrams-pmilexicon.txt")
sent140_unigrams=readLines("documents/RCode/sent140/unigrams-pmilexicon.txt")
?readLines
setwd("documents/RCode/sent140")
getwd()
?chgwd
?chwd
setwd("sent140")
getwd()
ls
ls()
list.files()
sent140_unigrams=readLines("unigrams-pmilexicon.txt")
setwd(..)
setwd(\)
setwd(documents)
setwd("documents")
getwd()
setwd("/Users")
setwd("/Users/wachibandara/")
setwd("/Users/wachibandara/Documents/RCode/sent140/")
setwd("/Users/wachibandara/Documents/RCode/sent140/")
sent140_unigrams=readLines("unigrams-pmilexicon.txt")
sent140_bigrams=readLines("bigrams-pmilexicon.txt")
sent140_pairs=readLines("pairs-pmilexicon.txt")
sent140_pairs
sent140_pairs[1,]
sent140_pairs[1]
sent140_bigrams[1,]
sent140_bigrams[1]
?readLines
sent140_unigrams=readLines("unigrams-pmilexicon.txt",sep="\t")
?read.table
sent140_unigrams=read.table("unigrams-pmilexicon.txt",sep="\t")
sent140_unigrams=read.table("unigrams-pmilexicon.txt",sep="\t",header=FALSE)
sent140_unigrams=readLines("unigrams-pmilexicon.txt",sep="\t",header=FALSE)
?readLines
sent140_unigrams=read.table("unigrams-pmilexicon.txt",sep="\t",header=FALSE)
sent140_unigrams=read.table("unigrams-pmilexicon.txt",sep="\t",header=FALSE,row.names=FALSE)
sent140_unigrams=read.table("unigrams-pmilexicon.txt",sep="\t",header=FALSE,row.names=FALSE,fill=TRUE)
sent140_unigrams=read.table("unigrams-pmilexicon.txt",sep="\t",header=FALSE,row.names=FALSE,fill=FALSE)
sent140_unigrams=read.table("unigrams-pmilexicon.txt",sep="\t",header=FALSE,row.names=FALSE,fill=!blank.lines.skip)
sent140_unigrams=read.table("unigrams-pmilexicon.txt",sep="\t",header=FALSE,row.names=FALSE,fill=blank.lines.skip)
sent140_unigrams=read.table("unigrams-pmilexicon.txt",sep="\t",header=FALSE,row.names=FALSE,fill = blank.lines.skip)
sent140_unigrams=read.delim("unigrams-pmilexicon.txt",sep="\t",header=FALSE,row.names=FALSE,fill=FALSE)
sent140_unigrams=read.delim("unigrams-pmilexicon.txt",sep="\t",header=FALSE)
sent140_unigrams
sent140_unigrams[1,]
sent140_unigrams[1,1:10]
sent140_unigrams[1,c(1,2,3,4)]
class(sent140_unigrams)
dim(sent140_unigrams)
setwd("/Users/wachibandara/Documents/RCode/sent140/")
sent140_unigrams = read.delim("unigrams-pmilexicon.txt",sep="\t",header=FALSE)
sent140_bigrams  = read.delim("bigrams-pmilexicon.txt",sep="\t",header=FALSE)
sent140_pairs    = read.delim("pairs-pmilexicon.txt",sep="\t",header=FALSE)
sent140_unigrams=read.delim("unigrams-pmilexicon.txt",sep="\t",header=FALSE)
names(sent140_bigrams)
sent140_bigrams[1,5]
sent140_bigrams[1,1]
head(sent140_bigrams)
head(sent140_unigrams)
sent140_allsent = rbind(sent140_unigrams, sent140_bigrams,sent140_pairs)
dim(sent140_allsent)
dim(sent140_pairs)
dim(sent140_unigrams)
dim(sent140_bigrams)
colnames(sent140_allsent)<-c("feature","sentimentScore","numPositive","numNegative")
head(sent140_allsent)
?match
sent_sorted<- sent140_allsent[order(sent140_allsent$sentimentScore),]
pos = sent_sorted[which(sent_sorted$sentimentScore > 0)]
neg = sent_sorted[which(sent_sorted$sentimentScore < 0)]
pos = sent_sorted[which(sent_sorted$sentimentScore > 0),]
neg = sent_sorted[which(sent_sorted$sentimentScore < 0),]
head(pos)
head(neg)
dim(pos)
dim(neg)
head(pos)
head(neg)
header(neg)
colnames(neg)
neg$feature[1]
neg$feature[2]
write.csv("temp.csv",sent140_allsent)
?write.csv
write.csv(sent140_allsent,"temp.csv")
dim(pos)
dim(pos)+dim)neg)
dim(pos)+dim(neg)
dim(sent140_allsent)
dim(sent140_unigrams)+dim(sent140_bigrams)+dim(sent140_pairs)
aal_txt[1]
debugSource('~/Documents/RCode/score.sentiment_Sent140.r')
debugSource('~/Documents/RCode/score.sentiment_Sent140.r')
debugSource('~/Documents/RCode/score.sentiment_Sent140.r')
debugSource('~/Documents/RCode/score.sentiment_Sent140.r')
